{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_ClassificaçãoTextos-BoW-TF-IDF.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufrpe-ensino/curso-mineracao-textos/blob/master/03_Classifica%C3%A7%C3%A3oTextos_BoW_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x9LVwe-LiMi"
      },
      "source": [
        "# Aprendizado Bayesiano: Naive Bayes\n",
        "\n",
        "O algoritmo Naive Bayes, assim como o KNN é um algoritmo de aprendizado com implementação relativamente simples, e que pode levar a resultados muito bons em determinados problemas de classificação. Este consiste em aplicar o teorema de Bayes, com a prerrogativa de independencia condicional entre cada par de atributos dado o valor da classe.\n",
        "\n",
        "Clique nos links para mais informações sobre o algoritmo [Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes) e sobre [classificação de textos](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html). com scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMvflrmwLnJl"
      },
      "source": [
        "# Exemplo: classificação de texto\n",
        "\n",
        "Neste exemplo, utilizaremos um dataset chamado 20newsgroups.\n",
        "\n",
        "O conjunto de dados é uma coleção de aproximadamente 20.000 documentos de grupos de notícias, particionados (quase) uniformemente em 20 grupos/categorias de notícias diferentes. Mais informações sobre esta base podem ser obtidas no repositório [UCI](http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups)\n",
        "\n",
        "As categorias existentes são:\n",
        "\n",
        "* 'alt.atheism',\n",
        "* 'comp.graphics',\n",
        "* 'comp.os.ms-windows.misc',\n",
        "* 'comp.sys.ibm.pc.hardware',\n",
        "* 'comp.sys.mac.hardware',\n",
        "* 'comp.windows.x',\n",
        "* 'misc.forsale',\n",
        "* 'rec.autos',\n",
        "* 'rec.motorcycles',\n",
        "* 'rec.sport.baseball',\n",
        "* 'rec.sport.hockey',\n",
        "* 'sci.crypt',\n",
        "* 'sci.electronics',\n",
        "* 'sci.med',\n",
        "* 'sci.space',\n",
        "* 'soc.religion.christian',\n",
        "* 'talk.politics.guns',\n",
        "* 'talk.politics.mideast',\n",
        "* 'talk.politics.misc',\n",
        "* 'talk.religion.misc'\n",
        "\n",
        "Neste exemplo, vamos considerar apenas duas categorias: '**alt.atheism**' e '**comp.graphics**'. O scitkit contém uma função que auxilia o download desta base:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeOVilr9NIUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cc56a8-07ed-4946-95f1-0292ec2d4c54"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Categorias selecionadas\n",
        "categories = [\n",
        "    'alt.atheism',\n",
        "    'comp.graphics',\n",
        "]\n",
        "\n",
        "print(\"Carregando 20 newsgroups dataset para as categorias:\")\n",
        "print(categories)\n",
        "\n",
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "twenty_test  = fetch_20newsgroups(subset='test',  categories=categories, shuffle=True, random_state=42)\n",
        "print(\"%d documents\" % len(twenty_train.filenames))\n",
        "print(\"%d categories\" % len(twenty_train.target_names))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando 20 newsgroups dataset para as categorias:\n",
            "['alt.atheism', 'comp.graphics']\n",
            "1064 documents\n",
            "2 categories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X4g3K1-UlcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd8c537-f542-42fe-9315-b5843b5021b9"
      },
      "source": [
        "# Visualizar os dados coletados\n",
        "print(twenty_train.keys())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TC-a8vReVU70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6273b7fa-adcb-4d14-c962-90210308bbc0"
      },
      "source": [
        "# Visualizando um dos documentos\n",
        "print(twenty_train['data'][0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: frank@D012S658.uucp (Frank O'Dwyer)\n",
            "Subject: Re: After 2000 years, can we say that Christian Morality is\n",
            "Organization: Siemens-Nixdorf AG\n",
            "Lines: 28\n",
            "NNTP-Posting-Host: d012s658.ap.mchp.sni.de\n",
            "\n",
            "In article <1993Apr15.125245.12872@abo.fi> MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka) writes:\n",
            "|In <1qie61$fkt@horus.ap.mchp.sni.de> frank@D012S658.uucp writes:\n",
            "|> In article <30114@ursa.bear.com> halat@pooh.bears (Jim Halat) writes:\n",
            "|\n",
            "|> #I'm one of those people who does not know what the word objective means \n",
            "|> #when put next to the word morality.  I assume its an idiom and cannot\n",
            "|> #be defined by its separate terms.\n",
            "|> #\n",
            "|> #Give it a try.\n",
            "|> \n",
            "|> Objective morality is morality built from objective values.\n",
            "|\n",
            "|      \"And these objective values are ... ?\"\n",
            "|Please be specific, and more importantly, motivate.\n",
            "\n",
            "I'll take a wild guess and say Freedom is objectively valuable.  I base\n",
            "this on the assumption that if everyone in the world were deprived utterly\n",
            "of their freedom (so that their every act was contrary to their volition),\n",
            "almost all would want to complain.  Therefore I take it that to assert or\n",
            "believe that \"Freedom is not very valuable\", when almost everyone can see\n",
            "that it is, is every bit as absurd as to assert \"it is not raining\" on\n",
            "a rainy day.  I take this to be a candidate for an objective value, and it\n",
            "it is a necessary condition for objective morality that objective values\n",
            "such as this exist.\n",
            "\n",
            "-- \n",
            "Frank O'Dwyer                                  'I'm not hatching That'\n",
            "odwyer@sse.ie                                  from \"Hens\",  by Evelyn Conlon\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKqq08LkczeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1f3ec4-c2d6-4b43-e762-3bf50448ec8a"
      },
      "source": [
        "# tamanho (sem preprocessamento)\n",
        "len(twenty_train['data'][0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1577"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1UM10zQPV_k"
      },
      "source": [
        "## Preprocessamento\n",
        "\n",
        "Como etapa de préprocessamento, iremos apenas nos limitar a remover palavras muito comuns, as chamadas *stopwords*. Uma lista de possíveis stopwords para inglês encontra-se abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtv0Xd7Pj8m"
      },
      "source": [
        "stopwords = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at',\n",
        "             'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by',  'can', \"can't\", 'cannot', 'could', \"couldn't\",\n",
        "             'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during','each', 'few', 'for', 'from', 'further',\n",
        "             'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\",\n",
        "             'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\",'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\",\n",
        "             'it', \"it's\", 'its', 'itself','1st', '2nd', '3rd','4th', '5th', '6th', '7th', '8th', '9th', '10th'\n",
        "             \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself','no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours' 'ourselves', 'out', 'over', 'own',\n",
        "             'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such',\n",
        "             'than', 'that',\"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\",\n",
        "             \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very',\n",
        "             'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where',\n",
        "             \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\",'will', 'with', \"won't\", 'would', \"wouldn't\",\n",
        "             'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves',\n",
        "             'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'hundred', 'thousand']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1ghOFTgKtzh"
      },
      "source": [
        "O código abaixo utiliza a biblioteca NLTK para fazer o pré-processamento dos textos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRtr11vNRMof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8250ad7b-2c7f-497b-c028-7495caeac989"
      },
      "source": [
        "import string\n",
        "from nltk.tokenize.regexp import RegexpTokenizer\n",
        "\n",
        "def preprocess(text):\n",
        "\n",
        "  # remover pontuações\n",
        "  text   = text.translate(string.punctuation)\n",
        "\n",
        "  # converter para lowercase\n",
        "  text = text.lower()\n",
        "\n",
        "  # tokenizar o texto em palavras\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(text.lower())\n",
        "\n",
        "  # filtrar palavras\n",
        "  tokens = [word for word in tokens\n",
        "            if word not in stopwords       # descartar stopwords\n",
        "                and len(word) > 3          # descartar palavras com menos de 3 caracteres\n",
        "                and not word[0].isdigit()] # descartar tokens contendo apenas numeros\n",
        "\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "X_train = []\n",
        "for doc in twenty_train['data']:\n",
        "  X_train.append(preprocess(doc))\n",
        "\n",
        "X_test = []\n",
        "for doc in twenty_test['data']:\n",
        "  X_test.append(preprocess(doc))\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frank d012s658 uucp frank dwyer subject years christian morality organization siemens nixdorf lines nntp posting host d012s658 mchp article mandtbacka finabo mats andtbacka writes horus mchp frank d012s658 uucp writes article ursa bear halat pooh bears halat writes people know word objective means next word morality assume idiom defined separate terms give objective morality morality built objective values objective values please specific importantly motivate take wild guess freedom objectively valuable base assumption everyone world deprived utterly freedom every contrary volition almost want complain therefore take assert believe freedom valuable almost everyone every absurd assert raining rainy take candidate objective value necessary condition objective morality objective values exist frank dwyer hatching odwyer hens evelyn conlon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxcZX12qc5Sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f60e5f-ed97-4c9f-cd2f-8ab80c37011d"
      },
      "source": [
        "# tamanho (com preprocessamento)\n",
        "len(X_train[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "846"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aH2nkY3Sv1N"
      },
      "source": [
        "### Exercício\n",
        "\n",
        "Converter o a função de preprocessamento acima para utilizar o SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h02NOJ7US8Dc"
      },
      "source": [
        "# sua resposta"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwUHXRvfMOc-"
      },
      "source": [
        "## Representação vetorial do texto\n",
        "\n",
        "Neste exemplo, utilizaremos o algoritmo Naive Bayes para classificar documentos de texto em categorias. Para isso, precisamos antes converter o texto para uma representação vetorial, ou seja, cada documento/exemplo precisa ser representado por um vetor de dimensões pré-definidas. Utilizaremos três técnicas básicas: BOW (*Bag of Words*), TF (*Term Frequency*) e TF-IDF (*Term Frequency - Inverse Document Frequency*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6o5yjjaPJCG"
      },
      "source": [
        "### BOW\n",
        "\n",
        "Consiste basicamente em contar quantas vezes cada palavra aparece no documento. Ou seja, sua aplicação a um conjunto de *n* documentos, produz uma matriz *n x d*, onde *d* corresponde ao tamanho do vocabulário considerado. No Scikit, esta representação é implementada pelo [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMmOZfv2SsZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26c692a-82f2-47c6-a034-74705451b75d"
      },
      "source": [
        "# Exemplo de uso do BOW no scikit\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
            "[[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtimrxTfTs8T"
      },
      "source": [
        "Aplicando ao nosso dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkcoN3_XTu-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8228f70c-4fa8-410b-d50a-5610becd31ca"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "bow_model  = vectorizer.fit(X_train)\n",
        "\n",
        "X_bow_train = bow_model.transform(X_train)\n",
        "X_bow_test  = bow_model.transform(X_test)\n",
        "\n",
        "print(X_bow_train.shape,X_bow_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1064, 17344) (708, 17344)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB-lp5d-Wej9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee0f80b-d176-4229-df2c-267809de246d"
      },
      "source": [
        "# matriz está armazenada em formato sparse\n",
        "print(X_bow_train[0,:])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 270)\t1\n",
            "  (0, 688)\t2\n",
            "  (0, 820)\t1\n",
            "  (0, 1104)\t2\n",
            "  (0, 1151)\t2\n",
            "  (0, 1174)\t1\n",
            "  (0, 1178)\t1\n",
            "  (0, 1473)\t1\n",
            "  (0, 1516)\t1\n",
            "  (0, 1519)\t1\n",
            "  (0, 1583)\t1\n",
            "  (0, 2127)\t1\n",
            "  (0, 2333)\t1\n",
            "  (0, 2722)\t1\n",
            "  (0, 3163)\t1\n",
            "  (0, 3275)\t1\n",
            "  (0, 3324)\t1\n",
            "  (0, 3460)\t1\n",
            "  (0, 3915)\t3\n",
            "  (0, 4152)\t1\n",
            "  (0, 4276)\t1\n",
            "  (0, 4931)\t2\n",
            "  (0, 5451)\t1\n",
            "  (0, 5463)\t2\n",
            "  (0, 5466)\t2\n",
            "  :\t:\n",
            "  (0, 11672)\t1\n",
            "  (0, 11791)\t1\n",
            "  (0, 11871)\t1\n",
            "  (0, 12549)\t1\n",
            "  (0, 12550)\t1\n",
            "  (0, 13841)\t1\n",
            "  (0, 14059)\t1\n",
            "  (0, 14468)\t1\n",
            "  (0, 14878)\t1\n",
            "  (0, 15229)\t3\n",
            "  (0, 15409)\t1\n",
            "  (0, 15501)\t1\n",
            "  (0, 16328)\t1\n",
            "  (0, 16383)\t1\n",
            "  (0, 16386)\t2\n",
            "  (0, 16418)\t2\n",
            "  (0, 16419)\t1\n",
            "  (0, 16421)\t3\n",
            "  (0, 16664)\t1\n",
            "  (0, 16755)\t1\n",
            "  (0, 16958)\t1\n",
            "  (0, 17070)\t2\n",
            "  (0, 17092)\t1\n",
            "  (0, 17133)\t3\n",
            "  (0, 17250)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6COLPTEVpJm"
      },
      "source": [
        "### *Term Frequency* (TF)\n",
        "A contagem de ocorrências (i.e., BOW) é um bom começo, mas há um problema: documentos mais longos terão valores de contagem média mais altos do que documentos mais curtos, embora possam falar sobre os mesmos tópicos.\n",
        "\n",
        "Para evitar essas possíveis discrepâncias, basta dividir o número de ocorrências de cada palavra em um documento pelo número total de palavras no documento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbJtPIvSVtke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac8b4c7-a8e2-4d02-ef06-2665d24a59cf"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=False)\n",
        "tf_model = vectorizer.fit(X_train)\n",
        "\n",
        "X_tf_train = tf_model.transform(X_train)\n",
        "X_tf_test  = tf_model.transform(X_test)\n",
        "\n",
        "print(X_tf_train[0,:])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 270)\t0.06454972243679027\n",
            "  (0, 688)\t0.12909944487358055\n",
            "  (0, 820)\t0.06454972243679027\n",
            "  (0, 1104)\t0.12909944487358055\n",
            "  (0, 1151)\t0.12909944487358055\n",
            "  (0, 1174)\t0.06454972243679027\n",
            "  (0, 1178)\t0.06454972243679027\n",
            "  (0, 1473)\t0.06454972243679027\n",
            "  (0, 1516)\t0.06454972243679027\n",
            "  (0, 1519)\t0.06454972243679027\n",
            "  (0, 1583)\t0.06454972243679027\n",
            "  (0, 2127)\t0.06454972243679027\n",
            "  (0, 2333)\t0.06454972243679027\n",
            "  (0, 2722)\t0.06454972243679027\n",
            "  (0, 3163)\t0.06454972243679027\n",
            "  (0, 3275)\t0.06454972243679027\n",
            "  (0, 3324)\t0.06454972243679027\n",
            "  (0, 3460)\t0.06454972243679027\n",
            "  (0, 3915)\t0.19364916731037085\n",
            "  (0, 4152)\t0.06454972243679027\n",
            "  (0, 4276)\t0.06454972243679027\n",
            "  (0, 4931)\t0.12909944487358055\n",
            "  (0, 5451)\t0.06454972243679027\n",
            "  (0, 5463)\t0.12909944487358055\n",
            "  (0, 5466)\t0.12909944487358055\n",
            "  :\t:\n",
            "  (0, 11672)\t0.06454972243679027\n",
            "  (0, 11791)\t0.06454972243679027\n",
            "  (0, 11871)\t0.06454972243679027\n",
            "  (0, 12549)\t0.06454972243679027\n",
            "  (0, 12550)\t0.06454972243679027\n",
            "  (0, 13841)\t0.06454972243679027\n",
            "  (0, 14059)\t0.06454972243679027\n",
            "  (0, 14468)\t0.06454972243679027\n",
            "  (0, 14878)\t0.06454972243679027\n",
            "  (0, 15229)\t0.19364916731037085\n",
            "  (0, 15409)\t0.06454972243679027\n",
            "  (0, 15501)\t0.06454972243679027\n",
            "  (0, 16328)\t0.06454972243679027\n",
            "  (0, 16383)\t0.06454972243679027\n",
            "  (0, 16386)\t0.12909944487358055\n",
            "  (0, 16418)\t0.12909944487358055\n",
            "  (0, 16419)\t0.06454972243679027\n",
            "  (0, 16421)\t0.19364916731037085\n",
            "  (0, 16664)\t0.06454972243679027\n",
            "  (0, 16755)\t0.06454972243679027\n",
            "  (0, 16958)\t0.06454972243679027\n",
            "  (0, 17070)\t0.12909944487358055\n",
            "  (0, 17092)\t0.06454972243679027\n",
            "  (0, 17133)\t0.19364916731037085\n",
            "  (0, 17250)\t0.06454972243679027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjQ0ITVjX8fV"
      },
      "source": [
        "### TF-IDF\n",
        "Usando o scikit, basta ativar o flag `use_idf=True`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWUoJsm_YFG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116dfef6-8d90-492c-b3b2-91fd1627c633"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(use_idf=True)\n",
        "tfidf_model = vectorizer.fit(X_train)\n",
        "\n",
        "X_tfidf_train = tfidf_model.transform(X_train)\n",
        "X_tfidf_test  = tfidf_model.transform(X_test)\n",
        "\n",
        "print(X_tfidf_train[0,:])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 17250)\t0.05108754590083216\n",
            "  (0, 17133)\t0.07038440047596704\n",
            "  (0, 17092)\t0.03821565526472219\n",
            "  (0, 17070)\t0.11139610459256753\n",
            "  (0, 16958)\t0.07626454293210316\n",
            "  (0, 16755)\t0.044336842602907205\n",
            "  (0, 16664)\t0.09332971272980163\n",
            "  (0, 16421)\t0.18426851344643358\n",
            "  (0, 16419)\t0.06704190953073146\n",
            "  (0, 16418)\t0.17678631906317366\n",
            "  (0, 16386)\t0.11325977875062908\n",
            "  (0, 16383)\t0.09065478158739082\n",
            "  (0, 16328)\t0.09332971272980163\n",
            "  (0, 15501)\t0.05440266710622901\n",
            "  (0, 15409)\t0.06753929622459243\n",
            "  (0, 15229)\t0.13624834793242538\n",
            "  (0, 14878)\t0.014671502314088931\n",
            "  (0, 14468)\t0.06753929622459243\n",
            "  (0, 14059)\t0.09660356385928208\n",
            "  (0, 13841)\t0.07626454293210316\n",
            "  (0, 12550)\t0.09332971272980163\n",
            "  (0, 12549)\t0.09065478158739082\n",
            "  (0, 11871)\t0.024500591419480536\n",
            "  (0, 11791)\t0.08176185874265679\n",
            "  (0, 11672)\t0.04027303037023522\n",
            "  :\t:\n",
            "  (0, 5466)\t0.11629797337199484\n",
            "  (0, 5463)\t0.10217509180166431\n",
            "  (0, 5451)\t0.09660356385928208\n",
            "  (0, 4931)\t0.14318469655813465\n",
            "  (0, 4276)\t0.09065478158739082\n",
            "  (0, 4152)\t0.060770663678054546\n",
            "  (0, 3915)\t0.21682460038831833\n",
            "  (0, 3460)\t0.07626454293210316\n",
            "  (0, 3324)\t0.09660356385928208\n",
            "  (0, 3275)\t0.08176185874265679\n",
            "  (0, 3163)\t0.08470599931549957\n",
            "  (0, 2722)\t0.05176221659617321\n",
            "  (0, 2333)\t0.09332971272980163\n",
            "  (0, 2127)\t0.06564356600717608\n",
            "  (0, 1583)\t0.04575601154133479\n",
            "  (0, 1519)\t0.08048527112380137\n",
            "  (0, 1516)\t0.08176185874265679\n",
            "  (0, 1473)\t0.07159234827906732\n",
            "  (0, 1178)\t0.0703157606602119\n",
            "  (0, 1174)\t0.0610931272588402\n",
            "  (0, 1151)\t0.18130956317478164\n",
            "  (0, 1104)\t0.053408004072319215\n",
            "  (0, 820)\t0.08316020226621217\n",
            "  (0, 688)\t0.11629797337199484\n",
            "  (0, 270)\t0.07721141999432092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTJq9ya-Yw0z"
      },
      "source": [
        "# Treinando modelo NaiveBayes (NB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYV00SwlbDhF"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW8Q3aN-axP_"
      },
      "source": [
        "## BOW + NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDOh6kBpbAN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba5f66e-71d1-486f-d2bf-57fe63d0df50"
      },
      "source": [
        "clf.fit(X_bow_train, twenty_train.target)\n",
        "\n",
        "acc = clf.score(X_bow_test , twenty_test.target)\n",
        "print('Acurácia: ', acc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia:  0.9788135593220338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PFI2MQ-a0_4"
      },
      "source": [
        "## TF + NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09QMVfd0buzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2d9025-e744-40a0-9c2f-5ba47eac1218"
      },
      "source": [
        "clf.fit(X_tf_train, twenty_train.target)\n",
        "\n",
        "acc = clf.score(X_tf_test , twenty_test.target)\n",
        "print('Acurácia: ', acc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia:  0.9731638418079096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgfiTAx8a2zk"
      },
      "source": [
        "## TF-IDF + NB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y24I7yk0Y2Wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d0f982-da74-4ad6-8e58-5648ff50dc36"
      },
      "source": [
        "clf.fit(X_tfidf_train, twenty_train.target)\n",
        "\n",
        "acc = clf.score(X_tfidf_test , twenty_test.target)\n",
        "print('Acurácia: ', acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia:  0.9774011299435028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzxDimJCaN-x"
      },
      "source": [
        "# Testando iterativamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BictP9Z9Z35L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3547967-8593-4146-c5ad-631d716ecf3e"
      },
      "source": [
        "docs = ['God is love', 'OpenGL on the GPU is fast']\n",
        "preprocessed_docs = [preprocess(doc) for doc in docs]\n",
        "\n",
        "print('\\nafter preprocessing:')\n",
        "print(preprocessed_docs)\n",
        "\n",
        "docs_preds = clf.predict(tfidf_model.transform(preprocessed_docs))\n",
        "\n",
        "print('\\npredictions:')\n",
        "for i,doc in enumerate(docs):\n",
        "    print('{} -> {}'.format(doc, twenty_train.target_names[docs_preds[i]]))\n",
        ""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "after preprocessing:\n",
            "['love', 'opengl fast']\n",
            "\n",
            "predictions:\n",
            "God is love -> alt.atheism\n",
            "OpenGL on the GPU is fast -> comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHy4D2kMaULb"
      },
      "source": [],
      "execution_count": 18,
      "outputs": []
    }
  ]
}